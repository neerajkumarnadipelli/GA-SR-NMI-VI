{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87e2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import heapq\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, mutual_info_score\n",
    "from skimage.metrics import structural_similarity as SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f3b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 1001, 138)\n",
      "(1001, 1001)\n",
      "Optimized image shape: (1001, 1001, 15)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "image = np.load(r\"C:\\Users\\NNadi\\Downloads\\Band_Selection_SR-NMI-VI\\cubert_drone_data\\images.npy\")  # Hyperspectral data (1217 × 303 × 274)\n",
    "labels = np.load(r\"C:\\Users\\NNadi\\Downloads\\Band_Selection_SR-NMI-VI\\cubert_drone_data\\labels.npy\")  # Ground truth (1217 × 303)\n",
    "print(image.shape)\n",
    "print(labels.shape)\n",
    "num_bands = image.shape[-1]  \n",
    "optimized_bands = [4, 136, 41, 106, 43, 46, 15, 47, 112, 50, 52, 23, 121, 62, 57]\n",
    "optimized_image = image[:, :, optimized_bands]\n",
    "np.save(r'C:\\Users\\NNadi\\Downloads\\images.npy', optimized_image)\n",
    "\n",
    "print(\"Optimized image shape:\", optimized_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dde7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 1001, 15)\n"
     ]
    }
   ],
   "source": [
    "t=np.load(r'C:\\Users\\NNadi\\Downloads\\images.npy')\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de22a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region = image[0:128, 0:128, :]\n",
    "nmi_matrix = np.zeros((num_bands, num_bands))\n",
    "ssim_matrix = np.zeros((num_bands, num_bands))\n",
    "dissimilarity_matrix = np.zeros((num_bands, num_bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c31a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 SR-NMI-VI Ranked Bands: [137  43  49  48  47  46  45  44  42  34  41  40  39  38  37  36  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  35  33 136\n",
      "   8  14  13  12  11  10   9   7  32   6   5   4   3   2   1  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  67  68  69 112\n",
      " 118 117 116 115 114 113 111  70 110 109 108 107 106 105 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132]\n"
     ]
    }
   ],
   "source": [
    "def calculate_entropy(data):\n",
    "    _, counts = np.unique(data, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    if len(probabilities) == 1:\n",
    "        return 0\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "def discretize_band(band, num_bins=256):\n",
    "    band_min = np.min(band)\n",
    "    band_max = np.max(band)\n",
    "    bins = np.linspace(band_min, band_max, num_bins)\n",
    "    discrete_band = np.digitize(band, bins) - 1 \n",
    "    return discrete_band\n",
    "for i in range(num_bands):\n",
    "    for j in range(i + 1, num_bands):\n",
    "        band_i = discretize_band(selected_region[:, :, i].flatten())\n",
    "        band_j = discretize_band(selected_region[:, :, j].flatten())\n",
    "        if len(np.unique(band_i)) > 1 and len(np.unique(band_j)) > 1:\n",
    "            mi = mutual_info_score(band_i, band_j)\n",
    "            h_i = calculate_entropy(band_i)\n",
    "            h_j = calculate_entropy(band_j)\n",
    "            if h_i > 0 and h_j > 0:\n",
    "                dissimilarity_matrix[i, j] = h_i + h_j - 2 * mi\n",
    "                dissimilarity_matrix[j, i] = dissimilarity_matrix[i, j]\n",
    "                nmi_matrix[i, j] = 2 * mi / (h_i + h_j)\n",
    "                nmi_matrix[j, i] = nmi_matrix[i, j]\n",
    "            ssim_value = SSIM(\n",
    "                selected_region[:, :, i],\n",
    "                selected_region[:, :, j],\n",
    "                data_range=selected_region[:, :, i].max() - selected_region[:, :, i].min()\n",
    "            )\n",
    "            ssim_matrix[i, j] = ssim_value\n",
    "            ssim_matrix[j, i] = ssim_value\n",
    "hybrid_similarity_matrix = nmi_matrix + ssim_matrix\n",
    "def rank_bands(sim_matrix, dis_matrix, num_bands_to_select=50):\n",
    "    avg_similarity = np.nanmean(sim_matrix, axis=1)\n",
    "    dissimilarity = np.nanmin(dis_matrix, axis=1)\n",
    "    range_similarity = avg_similarity.max() - avg_similarity.min()\n",
    "    range_dissimilarity = dissimilarity.max() - dissimilarity.min()\n",
    "    normalized_similarity = (avg_similarity - avg_similarity.min()) / range_similarity if range_similarity != 0 else np.zeros_like(avg_similarity)\n",
    "    normalized_dissimilarity = (dissimilarity - dissimilarity.min()) / range_dissimilarity if range_dissimilarity != 0 else np.zeros_like(dissimilarity)\n",
    "    scores = normalized_similarity * normalized_dissimilarity\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    return ranked_indices[:num_bands_to_select]\n",
    "num_bands_to_select = 100\n",
    "sr_nmi_vi_ranked_bands = rank_bands(nmi_matrix, dissimilarity_matrix, num_bands_to_select)\n",
    "\n",
    "print(f\"Top {num_bands_to_select} SR-NMI-VI Ranked Bands: {sr_nmi_vi_ranked_bands}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5554d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0: 1253 samples\n",
      "Class 1.0: 245 samples\n",
      "Class 2.0: 541 samples\n",
      "Class 3.0: 1961 samples\n"
     ]
    }
   ],
   "source": [
    "labels_flat = labels.flatten()\n",
    "labels_flat=labels_flat[0:4000]\n",
    "unique_classes, class_counts = np.unique(labels_flat, return_counts=True)\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class {cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca610df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tmax    \n",
      "0  \t50    \t2.98327\n",
      "1  \t38    \t2.98327\n",
      "2  \t34    \t2.9857 \n",
      "3  \t33    \t2.98569\n",
      "4  \t31    \t2.98569\n",
      "5  \t36    \t2.98806\n",
      "6  \t39    \t2.98566\n",
      "7  \t30    \t2.98566\n",
      "8  \t34    \t2.98566\n",
      "9  \t35    \t2.98566\n",
      "10 \t40    \t2.98567\n",
      "11 \t33    \t2.98567\n",
      "12 \t43    \t2.98327\n",
      "13 \t40    \t2.98092\n",
      "14 \t39    \t2.98807\n",
      "15 \t37    \t2.98807\n",
      "16 \t35    \t2.98329\n",
      "17 \t41    \t2.98569\n",
      "18 \t41    \t2.98808\n",
      "19 \t39    \t2.99045\n",
      "20 \t37    \t2.99045\n",
      "21 \t40    \t2.99045\n",
      "22 \t40    \t2.99284\n",
      "23 \t32    \t2.99284\n",
      "24 \t37    \t2.99284\n",
      "25 \t38    \t2.99284\n",
      "26 \t38    \t2.99284\n",
      "27 \t39    \t2.99284\n",
      "28 \t41    \t2.99047\n",
      "29 \t41    \t2.99047\n",
      "30 \t30    \t2.99047\n",
      "31 \t45    \t2.99047\n",
      "32 \t41    \t2.99047\n",
      "33 \t35    \t2.98806\n",
      "34 \t45    \t2.98329\n",
      "35 \t44    \t2.99045\n",
      "36 \t34    \t2.98566\n",
      "37 \t32    \t2.98327\n",
      "38 \t36    \t2.98566\n",
      "39 \t40    \t2.98806\n",
      "40 \t33    \t2.99284\n",
      "41 \t40    \t2.98807\n",
      "42 \t36    \t2.98807\n",
      "43 \t41    \t2.98567\n",
      "44 \t35    \t2.98806\n",
      "45 \t41    \t2.99045\n",
      "46 \t36    \t2.99045\n",
      "47 \t38    \t2.99045\n",
      "48 \t43    \t2.99045\n",
      "49 \t33    \t2.99045\n",
      "50 \t38    \t2.99045\n",
      "Optimized Bands (GA-Wrapped SR-NMI-VI): [4, 136, 41, 106, 43, 46, 15, 47, 112, 50, 52, 23, 121, 62, 57]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "\n",
    "POP_SIZE = 50   \n",
    "N_GEN = 50     \n",
    "MUTATION_RATE = 0.2\n",
    "CROSSOVER_RATE = 0.7\n",
    "MIN_BANDS = 10  \n",
    "MAX_BANDS = 20 \n",
    "sr_nmi_vi_ranked_bands = sr_nmi_vi_ranked_bands.tolist() if isinstance(sr_nmi_vi_ranked_bands, np.ndarray) else sr_nmi_vi_ranked_bands\n",
    "try:\n",
    "    del creator.FitnessMax\n",
    "    del creator.Individual\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Initialize an individual with a random number of bands between MIN_BANDS and MAX_BANDS\n",
    "def init_individual():\n",
    "    num_selected_bands = random.randint(MIN_BANDS, MAX_BANDS)\n",
    "    return creator.Individual(random.sample(sr_nmi_vi_ranked_bands, num_selected_bands))\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", init_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Mutation: Replace one band while maintaining the length constraint\n",
    "def mutate_individual(individual):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        idx_to_replace = random.randint(0, len(individual) - 1)\n",
    "        available_bands = list(set(sr_nmi_vi_ranked_bands) - set(individual))\n",
    "        if available_bands:\n",
    "            individual[idx_to_replace] = random.choice(available_bands)\n",
    "    return (individual,)\n",
    "\n",
    "# Crossover: Ensure the number of bands remains within constraints\n",
    "def crossover(parent1, parent2):\n",
    "    crossover_point = random.randint(1, min(len(parent1), len(parent2)) - 1)\n",
    "    \n",
    "    child1_genes = list(set(parent1[:crossover_point] + parent2[crossover_point:]))\n",
    "    child2_genes = list(set(parent2[:crossover_point] + parent1[crossover_point:]))\n",
    "\n",
    "    # Ensure valid band count\n",
    "    child1_genes = child1_genes[:MAX_BANDS] if len(child1_genes) > MAX_BANDS else child1_genes\n",
    "    child2_genes = child2_genes[:MAX_BANDS] if len(child2_genes) > MAX_BANDS else child2_genes\n",
    "    \n",
    "    # Fill up to MIN_BANDS if needed\n",
    "    while len(child1_genes) < MIN_BANDS:\n",
    "        new_band = random.choice(sr_nmi_vi_ranked_bands)\n",
    "        if new_band not in child1_genes:\n",
    "            child1_genes.append(new_band)\n",
    "    \n",
    "    while len(child2_genes) < MIN_BANDS:\n",
    "        new_band = random.choice(sr_nmi_vi_ranked_bands)\n",
    "        if new_band not in child2_genes:\n",
    "            child2_genes.append(new_band)\n",
    "\n",
    "    return creator.Individual(child1_genes), creator.Individual(child2_genes)\n",
    "\n",
    "# Fitness function using SVM classification\n",
    "def evaluate(individual):\n",
    "    selected_indices = list(individual)\n",
    "    X = image.reshape(-1, num_bands)[:, selected_indices]\n",
    "    y = labels.ravel()\n",
    "    X = X[0:5000, :]\n",
    "    y = y[0:5000]\n",
    "    unique_classes = np.unique(y)\n",
    "    if len(unique_classes) < 2:\n",
    "        return (0,)  \n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    except ValueError:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        return (0,)\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    return (acc + kappa + f1,)\n",
    "\n",
    "toolbox.register(\"mate\", crossover)\n",
    "toolbox.register(\"mutate\", mutate_individual)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "def run_ga():\n",
    "    pop = toolbox.population(n=POP_SIZE)\n",
    "    hof = tools.HallOfFame(1)  \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=CROSSOVER_RATE, mutpb=MUTATION_RATE, \n",
    "                        ngen=N_GEN, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "    return hof[0]  \n",
    "\n",
    "best_individual = run_ga()\n",
    "print(f\"Optimized Bands (GA-Wrapped SR-NMI-VI): {best_individual}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90095898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.9950, Kappa: 0.9923, F1-score: 0.9950\n",
      "Naïve Bayes - Accuracy: 0.7507, Kappa: 0.6391, F1-score: 0.7614\n",
      "SVM - Accuracy: 0.9951, Kappa: 0.9925, F1-score: 0.9951\n",
      "Random Forest - Accuracy: 0.9980, Kappa: 0.9969, F1-score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = image.reshape(-1, num_bands)[:, best_individual]\n",
    "y = labels.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "classifiers = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naïve Bayes\": GaussianNB(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    print(f\"{name} - Accuracy: {acc:.4f}, Kappa: {kappa:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb3faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision Tree - Accuracy: 0.9920, Kappa: 0.9877, F1-score: 0.9920\n",
    "Naïve Bayes - Accuracy: 0.7230, Kappa: 0.6009, F1-score: 0.7316\n",
    "SVM - Accuracy: 0.9888, Kappa: 0.9829, F1-score: 0.9888\n",
    "Random Forest - Accuracy: 0.9971, Kappa: 0.9956, F1-score: 0.9971"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
